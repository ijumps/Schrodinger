<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
  
  
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site: ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="https://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; </span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="Debug.html">Debug</a></li>
        
            <li><a href="Intro.html">Intro</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="15593933004313.html">
                
                  <h1>Intro to Kind</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>Kubernetes IN Docker - local clusters for testing Kubernetes</p>

<h2 id="toc_0">Brief</h2>

<p><a href="https://github.com/kubernetes-sigs/kind">Kind(Kubernetes IN Docker)</a> 是一个用来快速创建和测试 <code>kubernetes</code> 的工具，<code>Kind</code> 把环境的依赖降低到了最小，仅需要机器安装了 <code>docker</code> 即可。</p>

<p><strong>Kind 可以做什么</strong></p>

<ul>
<li>快速创建一个或多个 <code>kubernetes</code> 集群（几分钟）</li>
<li>支持 <code>ha master</code> 部署高可用的 <code>kubernetes</code> 集群</li>
<li>支持从源码构建并部署一个 <code>kubernetes</code> 集群</li>
<li>可以快速低成本体验一个最新的 <code>kubernetes</code> 集群，并支持 <code>kubernetes</code> 的绝大部分功能</li>
<li>支持本地离线运行一个多节点集群</li>
</ul>

<p><strong>Kind 有哪些优势</strong></p>

<ul>
<li>最小的安装依赖，仅需要安装 <code>docker</code> 即可</li>
<li>使用快速简单，使用 <code>kind cli</code> 工具即可快速创建集群</li>
<li>使用 <code>container</code> 来 mock <code>kubernetes node</code></li>
<li>内部使用 <code>kubeadm</code> 的官方主流部署工具</li>
<li>使用了 <code>containerd</code></li>
<li>通过了 <code>cncf</code> 官方的 <code>k8s conformance</code> 测试</li>
</ul>

<h2 id="toc_1">Usage</h2>

<pre><code class="language-text">GO111MODULE=&quot;on&quot; go get sigs.k8s.io/kind@v0.3.0 &amp;&amp; kind create cluster
</code></pre>

<h2 id="toc_2">How it work</h2>

<p><code>Kind</code> 使用一个 <code>container</code> 来模拟一个 <code>node</code>，在 <code>container</code> 里面跑了 <code>systemd</code> ，并用 <code>systemd</code> 托管了 <code>kubelet</code> 以及 <code>containerd</code>，然后容器内部的 <code>kubelet</code> 把其他 k8s 组件，比如 <code>kube-apiserver</code>, <code>etcd</code>, <code>cni</code> 等组件跑起来</p>

<p>可以通过配置文件的方式，来通过创建多个 <code>container</code> 的方式，来模拟创建多个 <code>node</code>，并以这些 <code>node</code> 来构建一个多节点的 <code>kubernetes</code> 集群</p>

<p><code>Kind</code> 内部使用了 <code>kubeadm</code> 这个工具来做集群的部署，包括 <code>ha master</code> 的高可用集群，也是借助 <code>kubeadm</code> 提供的 <code>aplha</code> 特性提供的。同时，在 <code>ha master</code> 下，额外部署了一个 <code>nginx</code> 用来提供负载均衡 <code>vip</code></p>

<p><img src="media/15593933004313/15593994593922.jpg" alt=""/><br/>
（<a href="https://kind.sigs.k8s.io/docs/design/initial/%EF%BC%89">https://kind.sigs.k8s.io/docs/design/initial/）</a></p>

<h3 id="toc_3">镜像构建</h3>

<p><code>Kind</code> 的镜像分为两个，一个 <code>base</code> 镜像，一个 <code>node</code> 镜像</p>

<p><strong>base 镜像</strong></p>

<p><code>base</code> 镜像目前使用了 <code>ubuntu:19.04</code> 作为基础镜像，做了下面的调整：</p>

<ul>
<li>安装 <code>systemd</code> 相关的包，并调整一些配置以适应在容器内运行</li>
<li>安装 <code>k8s</code> 运行时的依赖包，比如 <code>conntrack</code> <code>socat</code> <code>cni</code></li>
<li>安装容器运行环境，比如 <code>containerd</code> <code>crictl</code></li>
<li>配置自己的 <code>ENTRYPOINT</code> 脚本，以适应和调整容器内运行的问题</li>
</ul>

<p>具体的逻辑，可以参考构建的 <a href="https://github.com/kubernetes-sigs/kind/blob/master/images/base/Dockerfile">Dockerfile</a></p>

<p><strong>node 镜像</strong></p>

<p><code>node</code> 镜像的构建比较复杂，目前是通过运行 <code>base</code> 镜像，并在 <code>base</code> 镜像内执行操作，再保存此容器内容为镜像的方式来构建的，包含的操作有：</p>

<ul>
<li>构建 <code>Kubernetes</code> 相关资源（比如二进制文件和镜像）</li>
<li>运行一个用于构建的容器</li>
<li>把构建的 <code>Kubernetes</code> 相关资源复制到容器里</li>
<li>调整部分组件配置参数，以支持在容器内运行</li>
<li>预先拉去运行环境需要的镜像</li>
<li>通过 <code>docker commit</code> 方式保存当前的构建容器为 <code>node</code> 镜像</li>
</ul>

<p>具体的逻辑，可以参考 <a href="https://github.com/kubernetes-sigs/kind/blob/master/pkg/build/node/node.go">node.go</a></p>

<h3 id="toc_4">集群创建</h3>

<p><code>Kind</code> 创建集群的基本过程为:</p>

<ol>
<li>根据传入的参数，来创建 <code>container</code>，分为 <code>control node</code> 和 <code>worker node</code> 两种（如果是 <code>ha master</code>，还有一个 <code>loadbalancer node</code>）</li>
<li>如果需要，配置 <code>loadbalancer</code> 的配置，主要是 <code>nginx</code> 配置文件</li>
<li>生成 <code>kubeadm</code> 配置</li>
<li>对于第一个控制节点，使用 <code>kubeadm init</code> 初始化单节点集群</li>
<li>配置安装 <code>cni</code> 插件</li>
<li>配置存储（实际是安装了一个使用 <code>hostpath</code> 的 <code>storageclass</code>）</li>
<li>其他的控制节点，通过 <code>kubeadm join --experimental-control-plane</code> 的方式来扩容控制节点</li>
<li>通过 <code>kubeadm join</code> 扩容其他的工作节点</li>
<li>等待集群创建完成</li>
<li>生成访问配置，打印使用帮助</li>
</ol>

<p>具体的创建流程，可以参考代码 <a href="https://github.com/kubernetes-sigs/kind/blob/master/pkg/cluster/internal/create/create.go#L55">create.go</a></p>

<p>这里关于每个容器，是如何作为 <code>node</code> 跑起来的，可以简单讲解些原理：</p>

<p>根据不同的角色，调用不同的函数创建节点</p>

<p>(<a href="https://github.com/kubernetes-sigs/kind/blob/master/pkg/cluster/internal/create/nodes.go#L196">https://github.com/kubernetes-sigs/kind/blob/master/pkg/cluster/internal/create/nodes.go#L196</a>)</p>

<pre><code class="language-text">// TODO(bentheelder): remove network in favor of []cri.PortMapping when that is in
func (d *nodeSpec) Create(clusterLabel string) (node *nodes.Node, err error) {
    // create the node into a container (docker run, but it is paused, see createNode)
    // TODO(bentheelder): decouple from config objects further
    switch d.Role {
    case constants.ExternalLoadBalancerNodeRoleValue:
        node, err = nodes.CreateExternalLoadBalancerNode(d.Name, d.Image, clusterLabel, d.APIServerAddress, d.APIServerPort)
    case constants.ControlPlaneNodeRoleValue:
        node, err = nodes.CreateControlPlaneNode(d.Name, d.Image, clusterLabel, d.APIServerAddress, d.APIServerPort, d.ExtraMounts)
    case constants.WorkerNodeRoleValue:
        node, err = nodes.CreateWorkerNode(d.Name, d.Image, clusterLabel, d.ExtraMounts)
    default:
        return nil, errors.Errorf(&quot;unknown node role: %s&quot;, d.Role)
    }
    return node, err
}
</code></pre>

<p>节点（容器）创建时，通过配置 <code>--privileged</code>，挂载 <code>tmpfs</code>，修改主机名等，来运行节点</p>

<p>(<a href="https://github.com/kubernetes-sigs/kind/blob/master/pkg/cluster/nodes/create.go#L124">https://github.com/kubernetes-sigs/kind/blob/master/pkg/cluster/nodes/create.go#L124</a>)</p>

<pre><code class="language-text">func createNode(name, image, clusterLabel, role string, mounts []cri.Mount, extraArgs ...string) (handle *Node, err error) {
    runArgs := []string{
        &quot;-d&quot;, // run the container detached
        &quot;-t&quot;, // allocate a tty for entrypoint logs
        // running containers in a container requires privileged
        // NOTE: we could try to replicate this with --cap-add, and use less
        // privileges, but this flag also changes some mounts that are necessary
        // including some ones docker would otherwise do by default.
        // for now this is what we want. in the future we may revisit this.
        &quot;--privileged&quot;,
        &quot;--security-opt&quot;, &quot;seccomp=unconfined&quot;, // also ignore seccomp
        &quot;--tmpfs&quot;, &quot;/tmp&quot;, // various things depend on working /tmp
        &quot;--tmpfs&quot;, &quot;/run&quot;, // systemd wants a writable /run
        // some k8s things want /lib/modules
        &quot;-v&quot;, &quot;/lib/modules:/lib/modules:ro&quot;,
        &quot;--hostname&quot;, name, // make hostname match container name
        &quot;--name&quot;, name, // ... and set the container name
        // label the node with the cluster ID
        &quot;--label&quot;, clusterLabel,
        // label the node with the role ID
        &quot;--label&quot;, fmt.Sprintf(&quot;%s=%s&quot;, constants.NodeRoleKey, role),
    }

    // pass proxy environment variables to be used by node&#39;s docker deamon
    proxyDetails := getProxyDetails()
    for key, val := range proxyDetails.Envs {
        runArgs = append(runArgs, &quot;-e&quot;, fmt.Sprintf(&quot;%s=%s&quot;, key, val))
    }

    // adds node specific args
    runArgs = append(runArgs, extraArgs...)

    if docker.UsernsRemap() {
        // We need this argument in order to make this command work
        // in systems that have userns-remap enabled on the docker daemon
        runArgs = append(runArgs, &quot;--userns=host&quot;)
    }

    err = docker.Run(
        image,
        docker.WithRunArgs(runArgs...),
        docker.WithMounts(mounts),
    )

    // we should return a handle so the caller can clean it up
    handle = FromName(name)
    if err != nil {
        return handle, errors.Wrap(err, &quot;docker run error&quot;)
    }

    return handle, nil
}
</code></pre>

<h2 id="toc_5">More</h2>

<p><code>Kind</code> 是一个比较简单有趣的项目，<code>Kind</code> 的 <a href="https://kind.sigs.k8s.io/docs/contributing/project-scope/">scope</a> 定的比较明确和具体，也定的比较小，其实借助 <code>Kind</code> 或者 <code>Kind</code> 的思想，可以做更多的事情，比如：</p>

<ul>
<li>在单节点部署自己的上层平台</li>
<li>借助容器 mock 节点的方式，优化现有的测试方案</li>
<li>自动化的部署测试</li>
<li>自动化的 e2e 测试</li>
</ul>

<p><strong>扩展阅读</strong></p>

<p><code>Kind</code> 借助 <code>kubeadm</code> 的新特性实现了 <code>ha master</code> 高可用集群，<code>kubeadm</code> 借助 <code>join</code> 的方式来扩容 <code>master</code> 节点达到 <code>ha master</code>，其实内部的实现方式也有好有坏，有兴趣的可以参考 <code>kubeadm</code> <a href="https://github.com/kubernetes/kubernetes/tree/master/cmd/kubeadm">源码</a></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/6/1</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Intro.html'>Intro</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15577602074843.html">
                
                  <h1>Intro to Tekton</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>Kubernetes-native CI/CD building blocks.</p>

<h2 id="toc_0">Install</h2>

<ol>
<li>获取一个 Kubernetes 集群，可以通过:
<ul>
<li>谷歌云上创建一个 <a href="https://cloud.google.com/kubernetes-engine/">GKE</a> 集群</li>
<li><a href="https://www.katacoda.com/courses/kubernetes/playground">k8s playground</a> 可以快速测试</li>
<li><a href="https://docs.docker.com/docker-for-mac/kubernetes/">docker for mac/windows</a> 新版的 docker 提供了一个 Kubernetes 集群，可以用于本地测试</li>
<li><a href="https://github.com/kubernetes-sigs/kind">kind</a> Kubernetes IN Docker 可以快速构建和安装 Kubernetes 集群，用于自动化测试</li>
</ul></li>
<li>（确保当前操作的用户有 cluster-admin 权限）</li>
<li>安装 Tekton: <code>kubectl apply --filename https://storage.googleapis.com/tekton-releases/latest/release.yaml</code></li>
</ol>

<h2 id="toc_1">Core concepts</h2>

<p><strong><a href="https://github.com/tektoncd/pipeline/blob/master/docs/tasks.md">Task</a></strong>: 作为 <code>pipeline</code> 的基本单位，定义了一组需要运行的操作(<code>steps</code>)；可以多个 task 组成 pipeline，也可以独立运行</p>

<p><strong><a href="https://github.com/tektoncd/pipeline/blob/master/docs/pipelines.md">Pipeline</a></strong>: 用来编排一个或多个 <code>task</code>，并配置运行 <code>task</code> 需要的资源以及参数</p>

<p><strong><a href="https://github.com/tektoncd/pipeline/blob/master/docs/taskruns.md">TaskRun</a></strong>: 用来关联和触发运行 <code>task</code></p>

<p><strong><a href="https://github.com/tektoncd/pipeline/blob/master/docs/pipelineruns.md">PipelineRun</a></strong>: 用来关联和触发运行 <code>pipeline</code></p>

<p><strong><a href="https://github.com/tektoncd/pipeline/blob/master/docs/resources.md">PipelineResource</a></strong>: 用来定义执行 <code>task</code> 或者 <code>pipeline</code> 时需要的资源，比如 git repo，镜像等</p>

<h2 id="toc_2">Workflow</h2>

<ol>
<li>定义自己的 Task，包括定义具体要运行的操作（<code>steps</code>），输入输出，数据卷和容器模板
<ul>
<li><code>steps</code> 提供了一个运行的容器环境，以及需要进行的操作；一个 <code>task</code> 可以有多个 <code>step</code>，每一个 <code>step</code> 顺序执行</li>
<li><code>inputs</code>/<code>outputs</code> 提供了执行流水线时需要的资源及变量配置，比如可以预先拉取好 git repo，build 镜像等</li>
<li><code>volumes</code> 提供数据卷给构建的容器使用，可以用于存储或者传递数据等，或者读取配置文件</li>
<li><code>containerTemplate</code> 提供模板的功能，比如定义环境变量，可以作用于每一个 step 的执行环境中</li>
</ul></li>
<li>创建 <code>TaskRun</code> 来关联和触发定义好的 <code>Task</code>
<ul>
<li>可以通过 <code>taskRef</code> 的方式来管理 <code>task</code>；或者直接通过 <code>inline</code> 的模式，定义 <code>task</code> 的 <code>taskSpec</code></li>
<li>可以指定 <code>serviceAccount</code> 来用于做认证（比如拉取 git 仓库的代码）；未指定时，默认使用当前 namespace 的 default service account</li>
<li>可以指定 <code>timeout</code> 来配置超时时间</li>
<li><code>inputs</code>/<code>outputs</code> 定义执行 <code>task</code> 时的变量以及资源</li>
<li>可以通过修改 <code>status</code> 为 <code>TaskRunCancelled</code> 来取消任务</li>
</ul></li>
<li>也可以定义自己的 <code>Pipeline</code>，通过流水线来编排多个 <code>task</code>
<ul>
<li><code>resources</code> 定义了执行 <code>pipeline</code> 时用到的资源</li>
<li><code>tasks</code> 定义了流水线要执行的任务以及任务的编排关系</li>
<li>通过 <code>from</code> 或 <code>runAfter</code> 可以隐示或者显示的定义执行的任务顺序</li>
<li>没有依赖或者顺序相关的任务，会并行执行</li>
<li><code>retries</code> 定义了任务失败时重试的次数，比如临时网络中断造成的构建失败；默认是不重试的</li>
</ul></li>
<li>创建 <code>PipelineRun</code> 来关联和触发定义好的 <code>Pipeline</code>
<ul>
<li>通过 <code>pipelineRef</code> 来管理 <code>pipeline</code></li>
<li>可以指定 <code>serviceAccount</code> 来用于做认证（比如拉取 git 仓库的代码）；未指定时，默认使用当前 namespace 的 default service account</li>
<li>可以指定 <code>timeout</code> 来配置超时时间</li>
<li>可以指定 <code>resources</code> 来定义执行 <code>pipeline</code> 时用到的资源</li>
<li>可以通过修改 <code>status</code> 为 <code>PipelineRunCancelled</code> 来取消流水线</li>
</ul></li>
</ol>

<h2 id="toc_3">Auth</h2>

<p>可以通过配置 <code>ServiceAccount</code> 以及关联的 <code>secret</code> 的方式，来方便配置用于访问 git 或者 docker 镜像仓库的认证信息。基本流程如下：</p>

<ol>
<li>创建一个 <code>ServiceAccount</code>，包含了用到的认证资源信息，通过给出 secret name 的方式，与实际的 auth 配置绑定</li>
<li>创建 <code>secret</code> ，包含 <code>basic-auth</code> 和 <code>ssh-auth</code> 两种方式，提供用于登陆镜像仓库或者访问 git 仓库需要的用户名密码信息；或者提供用于访问git 仓库的 ssh key 信息</li>
<li>在创建 <code>TaskRun</code> 或者 <code>PipelineRun</code> 时，指定使用的 <code>ServiceAccount</code>。在后续执行 <code>task</code> 时，会在执行 <code>task</code> 前，预先把认证的配置文件，放置到运行的容器环境中</li>
<li>在执行 <code>task</code> 时，直接拉去代码仓库或者镜像仓库即可 </li>
</ol>

<h2 id="toc_4">In one map</h2>

<p><img src="media/15575319484864/tekton-one-map.png" alt="tekton-one-map"/></p>

<h2 id="toc_5">Demo(TODO)</h2>

<h3 id="toc_6">build tekton with tekton</h3>

<h3 id="toc_7">build k8s from source and run conformance test with tekton and kind</h3>

<h2 id="toc_8">Anything except the tekton core</h2>

<ul>
<li>UI: 提供创建和管理的界面 e.g. <a href="https://github.com/tektoncd/dashboard">dashboard</a></li>
<li>多租户: 支持不同用户、不同租户的权限控制和管理</li>
<li>资源 qos: 限制资源消耗，保证集群稳定性</li>
<li>API: 提供 api 接口供外部调用，比如使用 <a href="https://github.com/caicloud/nirvana">nirvana</a></li>
<li>trigger: 支持 github gitlib 条件或者手动触发</li>
<li>plugin: 支持 plugin 功能以支持更多的需求，比如 svn 的处理</li>
</ul>

<h2 id="toc_9">Next</h2>

<p><a href="https://github.com/caicloud/cyclone">cyclone</a></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/5/13</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Intro.html'>Intro</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15463555031437.html">
                
                  <h1>Debug for go program (kubelet open random port)</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">缘起</h2>

<p>发现某个版本开始，<code>kubelet</code> 每次运行后，会启动一个随机的 TCP 端口，绑定到 <code>127.0.0.1</code> 的本地端口上，可以通过 http 方式访问，返回都是 <code>404</code>，比如像下面这样的：</p>

<pre><code class="language-text">[root@dev test]# ss -lptn | grep kubelet
LISTEN     0      128    127.0.0.1:10248                    *:*                   users:((&quot;kubelet&quot;,pid=5854,fd=20))
LISTEN     0      128    127.0.0.1:37231                    *:*                   users:((&quot;kubelet&quot;,pid=5854,fd=7))
LISTEN     0      128         :::10250                   :::*                   users:((&quot;kubelet&quot;,pid=5854,fd=17))
LISTEN     0      128         :::10255                   :::*                   users:((&quot;kubelet&quot;,pid=5854,fd=19))
[root@dev test]# curl 127.0.0.1:37231/hi
404: Page Not Found
</code></pre>

<p>非固定端口的形式十分诡异，所以想要弄明白怎么回事。</p>

<h2 id="toc_1">破案</h2>

<h3 id="toc_2">google first</h3>

<p>尝试以 <code>kubelet</code> <code>kubernetes</code> <code>k8s</code> <code>random port</code> <code>127.0.0.1</code> <code>localhost</code> 等关键字搜索，好像没什么相关内容</p>

<h3 id="toc_3">upstream then</h3>

<p>去翻了下社区 <a href="https://github.com/kubernetes/kubernetes/issues">issue</a> ，以上面关键字搜索，好像也没什么相关内容</p>

<h3 id="toc_4">how to</h3>

<p>既然不是已知问题，那么就尝试从现象来找线索</p>

<p><strong>对象</strong>: <code>kubelet</code> 进程，是一个 golang 编写的程序<br/>
<strong>行为</strong>: 监听了<strong>本地随机</strong>端口，协议是 <strong>tcp</strong></p>

<p><strong>线索</strong>:</p>

<ol>
<li><code>随机</code> 代表在 listen 时，1. 指定了一个随机端口；2. 指定的端口是 <code>0</code></li>
<li><code>golang</code> go 程序里面的监听某个端口的行为，通常是调用的 <code>net.Listen()</code> 方法</li>
</ol>

<h3 id="toc_5">next</h3>

<p>通常，debug 到这一步时，<code>next</code> 就没有固定套路了。</p>

<p>比如，尝试搜索 <code>kubernetes</code> 源码里面，所有涉及 <code>net.Listen()</code> 调用的地方，筛选可能的配置端口是 <code>0</code> 的地方，发现了一些有趣的测试代码包含 <code>net.Listen(&quot;tcp&quot;, &quot;127.0.0.1:0&quot;)</code> 这类随机端口，是用来测试的</p>

<h3 id="toc_6">more</h3>

<p>通常，debug 到这个节点，会有些不管正确还是错误的猜测，需要更多的信息来验证和排查。这个时候，可以人造些线索，比如：</p>

<ol>
<li>调高 <code>kubelet</code> 日志等级，看看能否提供更多的信息</li>
<li>访问一个固定的 path ，比如 <code>127.0.0.1:37231/hahaha</code>，看看日志里面是否会出现</li>
<li>尝试通过 <code>strace</code> 来看看发生了啥（单 <code>strace</code> 是 syscall 级别的，信息不一定有用；比如能看到 <code>hahaha</code> 关键字了，但是在 <code>read</code> <code>write</code> 的 syscall 里，还是不知道发生了什么）</li>
</ol>

<h3 id="toc_7">again</h3>

<p>到这里，看来常规途径都没啥好的线索，那么还是回到最初的<strong>确定</strong>的现象</p>

<blockquote>
<p>发现某个版本开始，<code>kubelet</code> 每次运行后，会启动一个随机的 TCP 端口，绑定到 <code>127.0.0.1</code> 的本地端口上，可以通过 http 方式访问，返回都是 <code>404</code></p>
</blockquote>

<p>既然上面用 <code>strace</code> 或者搜索源码都不太好找到线索，那么可以换个思路，或是换个工具</p>

<p>比如这里幻想着一个工具：</p>

<ol>
<li>可以调试运行中的软件</li>
<li>可以在指定的地方触发</li>
<li>可以打印运行的参数/内存</li>
</ol>

<p>这么想想 ，好像 <code>gdb</code> 是做这么一件事的利器。但是，<code>gdb</code> 好用么？？？</p>

<h3 id="toc_8">Delve</h3>

<p>曾经用 <code>gdb</code> 调试过 <code>kubelet</code>，因为默认 release 版本的 <code>kubelet</code> 缺少调试的符号表，使用起来太过困难。</p>

<p>依旧 google 一波，关键字 <code>golang debug</code>，发现官方的 <a href="https://golang.org/doc/gdb">Debugging Go Code with GDB</a> 上面推荐了一个工具，叫做 <a href="https://github.com/derekparker/delve">Delve</a></p>

<p>Delve 的安装和使用文档就不多说，参考官方文档就好 </p>

<p>尝试了一波，确实方便和强大，但还有最后一个问题，<strong>断点打在哪里呢</strong>？需要在监听这个端口的调用那里来打一个断点，来确认是这个调用监听的这个端口；但如果知道了这个调用在哪，我还打断点干啥。</p>

<p>如果解决<code>鸡生蛋蛋生鸡</code>的问题呢？不管鸡也不管蛋，直接断点到 <code>net.Listen</code> 这个调用</p>

<h2 id="toc_9">Debug</h2>

<p>（正文开始了）</p>

<p>找好了工具，确定了方法，下面 debug 过程就顺风顺水了</p>

<p>加入 <code>cmd/kubelet</code> 目录，debug 模式运行 kubelet</p>

<pre><code class="language-text">[root@dev kubelet]# cd ~/go/src/k8s.io/kubernetes/cmd/kubelet/
[root@dev kubelet]# dlv debug .
Type &#39;help&#39; for list of commands.
(dlv)
</code></pre>

<p>设置断点</p>

<pre><code class="language-text">(dlv) break net.Listen
Breakpoint 1 set at 0x61da48 for net.Listen() /usr/local/go/src/net/dial.go:672
</code></pre>

<p>等待断点触发</p>

<pre><code class="language-text">(dlv) continue
...
&gt; net.Listen() /usr/local/go/src/net/dial.go:672 (hits goroutine(1):1 total:2) (PC: 0x61da48)
&gt; net.Listen() /usr/local/go/src/net/dial.go:672 (hits goroutine(98):1 total:2) (PC: 0x61da48)
   667: // The Addr method of Listener can be used to discover the chosen
   668: // port.
   669: //
   670: // See func Dial for a description of the network and address
   671: // parameters.
=&gt; 672: func Listen(network, address string) (Listener, error) {
   673:         var lc ListenConfig
   674:         return lc.Listen(context.Background(), network, address)
   675: }
   676:
   677: // ListenPacket announces on the local network address.
(dlv)
</code></pre>

<p>打印 listen 信息</p>

<pre><code class="language-text">(dlv) p address
&quot;localhost:0&quot;
</code></pre>

<p>查看调用栈</p>

<pre><code class="language-text">(dlv) bt
0  0x000000000061da48 in net.Listen
   at /usr/local/go/src/net/dial.go:672
1  0x00000000025448f6 in k8s.io/kubernetes/pkg/kubelet/server/streaming.(*server).Start
   at /root/go/src/k8s.io/kubernetes/pkg/kubelet/server/streaming/server.go:238
2  0x00000000041b1a12 in k8s.io/kubernetes/pkg/kubelet/dockershim.(*dockerService).Start.func1
   at /root/go/src/k8s.io/kubernetes/pkg/kubelet/dockershim/docker_service.go:400
3  0x0000000000466451 in runtime.goexit
   at /usr/local/go/src/runtime/asm_amd64.s:1333
</code></pre>

<p>分步执行，并对比前后 <code>ss -lptn</code> 的变化</p>

<pre><code class="language-text">(dlv) n
&gt; net.Listen() /usr/local/go/src/net/dial.go:674 (PC: 0x61da7e)
   669: //
   670: // See func Dial for a description of the network and address
   671: // parameters.
   672: func Listen(network, address string) (Listener, error) {
   673:         var lc ListenConfig
=&gt; 674:         return lc.Listen(context.Background(), network, address)
   675: }
   676:
   677: // ListenPacket announces on the local network address.
   678: //
   679: // The network must be &quot;udp&quot;, &quot;udp4&quot;, &quot;udp6&quot;, &quot;unixgram&quot;, or an IP
(dlv)

---

[root@dev test]# ss -lptn
State       Recv-Q Send-Q     Local Address:Port                    Peer Address:Port
LISTEN      0      128                    *:22                                 *:*                   users:((&quot;sshd&quot;,pid=3360,fd=3))
LISTEN      0      100            127.0.0.1:25                                 *:*                   users:((&quot;master&quot;,pid=3728,fd=13))
LISTEN      0      128                   :::22                                :::*                   users:((&quot;sshd&quot;,pid=3360,fd=4))
LISTEN      0      100                  ::1:25                                :::*                   users:((&quot;master&quot;,pid=3728,fd=14))

---

(dlv) n
&gt; k8s.io/kubernetes/pkg/kubelet/server/streaming.(*server).Start() /root/go/src/k8s.io/kubernetes/pkg/kubelet/server/streaming/server.go:238 (PC: 0x25448f6)
Values returned:
        ~r2: net.Listener(*net.TCPListener) *{
                fd: *net.netFD {
                        pfd: (*internal/poll.FD)(0xc00030fa80),
                        family: 2,
                        sotype: 1,
                        isConnected: false,
                        net: &quot;tcp&quot;,
                        laddr: net.Addr(*net.TCPAddr) ...,
                        raddr: net.Addr nil,},}
        ~r3: error nil

   233:         if !stayUp {
   234:                 // TODO(tallclair): Implement this.
   235:                 return errors.New(&quot;stayUp=false is not yet implemented&quot;)
   236:         }
   237:
=&gt; 238:         listener, err := net.Listen(&quot;tcp&quot;, s.config.Addr)
   239:         if err != nil {
   240:                 return err
   241:         }
   242:         // Use the actual address as baseURL host. This handles the &quot;0&quot; port case.
   243:         s.config.BaseURL.Host = listener.Addr().String()
(dlv)

---

[root@dev test]# ss -lptn
State       Recv-Q Send-Q     Local Address:Port                    Peer Address:Port
LISTEN      0      128                    *:22                                 *:*                   users:((&quot;sshd&quot;,pid=3360,fd=3))
LISTEN      0      100            127.0.0.1:25                                 *:*                   users:((&quot;master&quot;,pid=3728,fd=13))
LISTEN      0      128            127.0.0.1:33375                              *:*                   users:((&quot;debug&quot;,pid=6847,fd=8))
LISTEN      0      128                   :::22                                :::*                   users:((&quot;sshd&quot;,pid=3360,fd=4))
LISTEN      0      100                  ::1:25                                :::*                   users:((&quot;master&quot;,pid=3728,fd=14))
</code></pre>

<p>到这里，就初步破案了，可以看到 <code>dockershim</code> 创建时，先启动了一个 <code>streaming server</code>，这个 <strong>kubelet random port</strong> 就是这个 <code>streaming server</code> 做的，初步看来是做 <code>exec attach portforward</code> 的</p>

<h2 id="toc_10">彩蛋</h2>

<p>上面用 <code>dlv</code> 去跟踪断点时，并不是每次查看到的 listen 地址都是 <code>&quot;localhost:0&quot;</code>，比如多跑几次，可以看到</p>

<pre><code class="language-text">&gt; net.Listen() /usr/local/go/src/net/dial.go:672 (hits goroutine(1):1 total:2) (PC: 0x61da48)
   667: // The Addr method of Listener can be used to discover the chosen
   668: // port.
   669: //
   670: // See func Dial for a description of the network and address
   671: // parameters.
=&gt; 672: func Listen(network, address string) (Listener, error) {
   673:         var lc ListenConfig
   674:         return lc.Listen(context.Background(), network, address)
   675: }
   676:
   677: // ListenPacket announces on the local network address.
(dlv) bt
 0  0x000000000061da48 in net.Listen
    at /usr/local/go/src/net/dial.go:672
 1  0x00000000018e22b5 in k8s.io/kubernetes/pkg/kubelet/util.CreateListener
    at /root/go/src/k8s.io/kubernetes/pkg/kubelet/util/util_unix.go:53
 2  0x00000000041b35c1 in k8s.io/kubernetes/pkg/kubelet/dockershim/remote.(*DockerServer).Start
    at /root/go/src/k8s.io/kubernetes/pkg/kubelet/dockershim/remote/docker_server.go:60
 3  0x00000000042791a8 in k8s.io/kubernetes/pkg/kubelet.NewMainKubelet
    at /root/go/src/k8s.io/kubernetes/pkg/kubelet/kubelet.go:640
 4  0x00000000042dabd6 in k8s.io/kubernetes/cmd/kubelet/app.CreateAndInitKubelet
    at ./app/server.go:1100
 5  0x00000000042d9efa in k8s.io/kubernetes/cmd/kubelet/app.RunKubelet
    at ./app/server.go:990
 6  0x00000000042d46fc in k8s.io/kubernetes/cmd/kubelet/app.run
    at ./app/server.go:707
 7  0x00000000042d2cf3 in k8s.io/kubernetes/cmd/kubelet/app.Run
    at ./app/server.go:412
 8  0x00000000042ddc53 in k8s.io/kubernetes/cmd/kubelet/app.NewKubeletCommand.func1
    at ./app/server.go:261
 9  0x000000000409ad8a in k8s.io/kubernetes/vendor/github.com/spf13/cobra.(*Command).execute
    at /root/go/src/k8s.io/kubernetes/vendor/github.com/spf13/cobra/command.go:760
10  0x000000000409b72b in k8s.io/kubernetes/vendor/github.com/spf13/cobra.(*Command).ExecuteC
    at /root/go/src/k8s.io/kubernetes/vendor/github.com/spf13/cobra/command.go:846
11  0x000000000409b02b in k8s.io/kubernetes/vendor/github.com/spf13/cobra.(*Command).Execute
    at /root/go/src/k8s.io/kubernetes/vendor/github.com/spf13/cobra/command.go:794
12  0x00000000042dfde6 in main.main
    at ./kubelet.go:43
13  0x0000000000435bd5 in runtime.main
    at /usr/local/go/src/runtime/proc.go:201
14  0x0000000000466451 in runtime.goexit
    at /usr/local/go/src/runtime/asm_amd64.s:1333
</code></pre>

<p>这是因为 <code>goroutine</code> 的原因，可能同时有多个地方触发了这个断点（这里就不破案了）；但是可能和 <code>dlv</code> 实现有关，只能断点到其中一个 <code>goroutine</code> 中，另外一个 <code>goroutine</code> 会继续跑（埋个坑）</p>

<p>如果查看断点时的 <code>goroutine</code>，就可以看到</p>

<pre><code class="language-text">(dlv) goroutines
* Goroutine 1 - User: /usr/local/go/src/net/dial.go:672 net.Listen (0x61da48) (thread 7034)
  Goroutine 2 - User: /usr/local/go/src/runtime/proc.go:303 runtime.gopark (0x435fb4)
  Goroutine 3 - User: /usr/local/go/src/runtime/proc.go:303 runtime.gopark (0x435fb4)
  Goroutine 4 - User: /usr/local/go/src/runtime/lock_futex.go:228 runtime.notetsleepg (0x40ec57)
  Goroutine 18 - User: /usr/local/go/src/runtime/proc.go:303 runtime.gopark (0x435fb4)
  Goroutine 19 - User: /usr/local/go/src/runtime/proc.go:303 runtime.gopark (0x435fb4)
  Goroutine 20 - User: /usr/local/go/src/runtime/proc.go:303 runtime.gopark (0x435fb4)
  Goroutine 21 - User: /root/go/src/k8s.io/kubernetes/vendor/k8s.io/klog/klog.go:941 k8s.io/kubernetes/vendor/k8s.io/klog.(*loggingT).flushDaemon (0x94e6d3)
  Goroutine 33 - User: /usr/local/go/src/runtime/sigqueue.go:139 os/signal.signal_recv (0x44bedc)
  Goroutine 46 - User: /usr/local/go/src/runtime/proc.go:303 runtime.gopark (0x435fb4)
  Goroutine 47 - User: /root/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/signal.go:36 k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.SetupSignalHandler.func1 (0x1846e64)
  Goroutine 48 - User: /root/go/src/k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:145 k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil (0x10b0f2a)
  Goroutine 63 - User: /usr/local/go/src/runtime/lock_futex.go:228 runtime.notetsleepg (0x40ec57)
  Goroutine 67 - User: /usr/local/go/src/runtime/netpoll.go:173 internal/poll.runtime_pollWait (0x4306ae)
  Goroutine 68 - User: /usr/local/go/src/net/http/transport.go:1885 net/http.(*persistConn).writeLoop (0x7ec84e)
  Goroutine 75 - User: /usr/local/go/src/runtime/netpoll.go:173 internal/poll.runtime_pollWait (0x4306ae)
  Goroutine 76 - User: /usr/local/go/src/net/http/transport.go:1885 net/http.(*persistConn).writeLoop (0x7ec84e)
  Goroutine 82 - User: /root/go/src/k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/watch/mux.go:207 k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/watch.(*Broadcaster).loop (0xb2c8e9)
  Goroutine 83 - User: /root/go/src/k8s.io/kubernetes/vendor/k8s.io/client-go/tools/record/event.go:231 k8s.io/kubernetes/vendor/k8s.io/client-go/tools/record.(*eventBroadcasterImpl).StartEventWatcher.func1 (0x18ea5d4)
  Goroutine 89 - User: /usr/local/go/src/net/dial.go:672 net.Listen (0x61da48) (thread 7016)
  Goroutine 90 - User: /root/go/src/k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:87 k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.Until (0x10b0d10)
[21 goroutines]
</code></pre>

<p>可以切换到我们需要 debug 的 <code>goroutine</code>，继续断点调试</p>

<pre><code class="language-text">(dlv) goroutine 89
Switched from 1 to 89 (thread 7016)
(dlv) bt
0  0x000000000061da48 in net.Listen
   at /usr/local/go/src/net/dial.go:672
1  0x00000000025448f6 in k8s.io/kubernetes/pkg/kubelet/server/streaming.(*server).Start
   at /root/go/src/k8s.io/kubernetes/pkg/kubelet/server/streaming/server.go:238
2  0x00000000041b1a12 in k8s.io/kubernetes/pkg/kubelet/dockershim.(*dockerService).Start.func1
   at /root/go/src/k8s.io/kubernetes/pkg/kubelet/dockershim/docker_service.go:400
3  0x0000000000466451 in runtime.goexit
   at /usr/local/go/src/runtime/asm_amd64.s:1333
</code></pre>

<h2 id="toc_11">后记</h2>

<p><strong>埋个坑</strong>，这段 <code>streaming server</code> 的逻辑还是比较诡异，也不知道是重构代码没删干净，还是真有在用；不知道有没有类似绕过 auth 的问题。。。</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/1/1</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Debug.html'>Debug</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <h1></h1>
                <div class="site-des"></div>
                <div class="social">











  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="Debug.html"><strong>Debug</strong></a>
        
            <a href="Intro.html"><strong>Intro</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15593933004313.html">Intro to Kind</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15577602074843.html">Intro to Tekton</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15463555031437.html">Debug for go program (kubelet open random port)</a>
			      </li>
		     
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    



  </body>
</html>
